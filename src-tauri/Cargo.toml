[package]
name = "bear-ai-llm"
version = "1.0.14"
description = "A secure, private AI assistant for legal professionals"
authors = ["Ernst van Gassen <ernst@example.com>"]
edition = "2021"

[build-dependencies]
tauri-build = { version = "2.4.1", features = [] }

[dependencies]
tauri = { version = "2.4.1", features = ["tray-icon"] }
tauri-plugin-fs = "2.4.2"
tauri-plugin-dialog = "2.4.0"
tauri-plugin-shell = "2.3.1"
tauri-plugin-os = "2.3.1"
tauri-plugin-updater = "2.4.0"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tokio = { version = "1", features = ["full"] }
reqwest = { version = "0.12", features = ["json"] }
regex = "1"
lazy_static = "1.5"
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt", "json"] }
tracing-appender = "0.2"
sysinfo = "0.37"
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1", features = ["v4", "serde"] }
async-trait = "0.1"
hf-hub = { version = "0.4", features = ["tokio"] }
dirs = "6.0"
urlencoding = "2.1"
walkdir = "2.5"
nvml-wrapper = "0.11"
zip = "0.6"
# AI/ML dependencies
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"
tokenizers = "0.21"
# Vector database
# faiss = { version = "0.12", optional = true } # Disabled - using fastembed instead
# Better embeddings - Use fastembed with compatible features
fastembed = { version = "5.0", default-features = false, features = ["online"] }
# ONNX runtime for NER models - ensure compatible runtime library
ort = { version = "2.0.0-rc.10", default-features = false, features = ["download-binaries", "half", "load-dynamic"] }
pdf-extract = "0.7"
rusqlite = { version = "0.31", features = ["bundled"] }
calamine = { version = "0.26", features = ["dates"] }
docx-rs = "0.4"
# Legacy format support
encoding_rs = "0.8"
cfb = "0.9"  # Compound File Binary format for DOC/PPT
# For now, we'll implement a mock inference engine
# Future: Add proper GGUF runtime like llama-cpp-rs when it's more stable

[features]
default = ["custom-protocol"]
custom-protocol = ["tauri/custom-protocol"]

[[bin]]
name = "bear-ai-llm"
path = "src/main.rs"
